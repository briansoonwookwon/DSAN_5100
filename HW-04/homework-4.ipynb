{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "format: \n",
    "    html: \n",
    "        embed-resources: true\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Markov chains\n",
    "\n",
    "**Author:** Brian Kwon\n",
    "\n",
    "* `IMPORTANT`: We have decided to \"shake it up\" and introduce a `python` assignment, as a break from `R`. \n",
    "* Therefore, this assignment MUST be done in `python`, NOT `R`\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Read and work through all tutorial content and do all exercises below\n",
    "  \n",
    "**Submission:**\n",
    "\n",
    "* You need to upload ONE document to Canvas when you are done\n",
    "  * (1) An HTML (or PDF) version of the completed form of this notebook \n",
    "* The final uploaded version should NOT have any code-errors present \n",
    "* All outputs must be visible in the uploaded version, including code-cell outputs, images, graphs, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "`Starter code`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PARAM SET\n",
    "m=3\n",
    "pu=0.2; pd=0.3; pl=0.25; pr=0.25\n",
    "p=[pu,pd,pl,pr]\n",
    "q=[0,0,0,0,1,0,0,0,0] #initial state probablities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "\n",
    "* Markov chains (MC) are important for understanding Markov Decision Processes, even though MC do not involve any decision-making. \n",
    "* MCs are mathematical models describing particular types of stochastic processes. \n",
    "* **Markov property:**  The next state only depends on the current state, NOT past states \n",
    "  * Denote the state at time $t$ by $s_t$\n",
    "$$p\\left(s_{t+1} \\mid s_t, s_{t-1}, s_{t-2}, \\ldots, s_0\\right)=p\\left(s_{t+1} \\mid s_t\\right)$$ \n",
    "  * i.e. regardless of the past trajectory, the next state only depends on the current state\n",
    "* **Markov chain:** A stochastic process where **ALL** states & times have the Markov property. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: The broken robot\n",
    "* Consider a robot which is stuck in a $m \\times m$ grid world and can only make random moves.\n",
    "* At EVERY step, the probability for up, down, left, and right is $\\mathbf p=(0.2, 0.3, 0.25, 0.25)$\n",
    "* You can think of $\\mathbf p=(0.2, 0.3, 0.25, 0.25)$ as the \"rules of the game\"\n",
    "* Assume that if the robot hits the wall, it bounces off and remains in the current state. However it's probabilities for the next steps are still the same as before.\n",
    "* Does the process have the Markov property? ... Yes! Since, the probability of the next transition depends only on the current state.   \n",
    "\n",
    "![](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.25*0.25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Transition matrix\n",
    "\n",
    "* **Initial probability distribution**: $\\mathbf q_0$ determines states the system starts in\n",
    "  * Discrete state set $\\rightarrow$ vector containing initialization probabilities for each state \n",
    "* **Transition probability matrix $P$** : Each row represents the probability of transition from an arbitrary state to all other possible states (extremely important MC quantity)\n",
    "- A process with $N$ possible states will result in a $N \\times N$ matrix\n",
    "$$\n",
    "\\begin{bmatrix} P_{1,1} & \\cdots & P_{1,n} \\\\ \\vdots & \\ddots & \\vdots \\\\ P_{n,1} & \\cdots & P_{n,n} \\end{bmatrix}\n",
    "$$\n",
    "- The probability of transitioning from state $1$ to state $n$ is $P_{1,n}$\n",
    "- The probability of transitioning from state $n$ to state $n$ is $P_{n,n}$\n",
    "- This pattern holds for any entry in the matrix: $s_2$ $\\rightarrow$ $s_3$ would be $P_{2,3}$ (row 2 column 3)\n",
    "- Mathematically defined as $P_{ij} = P(s_{t+1} = j, s_t = i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergodicity\n",
    "\n",
    "Time Averages vs. Ensemble Averages: \n",
    "\n",
    "* In many situations, you might be interested in understanding the behavior of a system over a long time (time averages) \n",
    "* or the behavior of multiple identical systems considered as a group (ensemble averages). \n",
    "* Ergodicity implies that these two types of averages will be equivalent, given enough time.\n",
    "\n",
    "Ergodicity refers to a property of a system or process in which time averages of a single system converge to ensemble averages of a collection of identical systems. It assumes that the system explores its entire state space over time, enabling meaningful equivalence between individual system behavior and group behavior."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition probability matrix\n",
    "\n",
    "* The following code can be used to compute the transition matrix, for the broken robot problem of arbitrary grid size.\n",
    "* This was used to compute the matrices from the previous examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRANSITION MATRIX: 3x3 \n",
      " [[0.45 0.25 0.   0.3  0.   0.   0.   0.   0.  ]\n",
      " [0.25 0.2  0.25 0.   0.3  0.   0.   0.   0.  ]\n",
      " [0.   0.25 0.45 0.   0.   0.3  0.   0.   0.  ]\n",
      " [0.2  0.   0.   0.25 0.25 0.   0.3  0.   0.  ]\n",
      " [0.   0.2  0.   0.25 0.   0.25 0.   0.3  0.  ]\n",
      " [0.   0.   0.2  0.   0.25 0.25 0.   0.   0.3 ]\n",
      " [0.   0.   0.   0.2  0.   0.   0.55 0.25 0.  ]\n",
      " [0.   0.   0.   0.   0.2  0.   0.25 0.3  0.25]\n",
      " [0.   0.   0.   0.   0.   0.2  0.   0.25 0.55]]\n"
     ]
    }
   ],
   "source": [
    "#SOURCE: 2020: Mastering reinforcement learning with python, enes bilgin (1st edition).\n",
    "def get_P(m, p):\n",
    "    p_up, p_down, p_left, p_right=p\n",
    "    #print(p_up, p_down, p_left, p_right)\n",
    "    m2 = m ** 2\n",
    "    P = np.zeros((m2, m2))\n",
    "    ix_map = {i + 1: (i // m, i % m) for i in range(m2)}\n",
    "    for i in range(m2):\n",
    "        for j in range(m2):\n",
    "            r1, c1 = ix_map[i + 1]\n",
    "            r2, c2 = ix_map[j + 1]\n",
    "            rdiff = r1 - r2\n",
    "            cdiff = c1 - c2\n",
    "            if rdiff == 0:\n",
    "                if cdiff == 1:\n",
    "                    P[i, j] = p_left\n",
    "                elif cdiff == -1:\n",
    "                    P[i, j] = p_right\n",
    "                elif cdiff == 0:\n",
    "                    if r1 == 0:\n",
    "                        P[i, j] = p_up\n",
    "                    elif r1 == m - 1:\n",
    "                        P[i, j] = p_down\n",
    "                    if c1 == 0:\n",
    "                        P[i, j] += p_left\n",
    "                    elif c1 == m - 1:\n",
    "                        P[i, j] += p_right\n",
    "            elif rdiff == 1:\n",
    "                if cdiff == 0:\n",
    "                    P[i, j] = p_up\n",
    "            elif rdiff == -1:\n",
    "                if cdiff == 0:\n",
    "                    P[i, j] = p_down\n",
    "    return P\n",
    "\n",
    "print(\"\\nTRANSITION MATRIX: 3x3 \\n\",get_P(m, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0->0' '0->1' '0->2' '0->3' '0->4' '0->5' '0->6' '0->7' '0->8']\n",
      " ['1->0' '1->1' '1->2' '1->3' '1->4' '1->5' '1->6' '1->7' '1->8']\n",
      " ['2->0' '2->1' '2->2' '2->3' '2->4' '2->5' '2->6' '2->7' '2->8']\n",
      " ['3->0' '3->1' '3->2' '3->3' '3->4' '3->5' '3->6' '3->7' '3->8']\n",
      " ['4->0' '4->1' '4->2' '4->3' '4->4' '4->5' '4->6' '4->7' '4->8']\n",
      " ['5->0' '5->1' '5->2' '5->3' '5->4' '5->5' '5->6' '5->7' '5->8']\n",
      " ['6->0' '6->1' '6->2' '6->3' '6->4' '6->5' '6->6' '6->7' '6->8']\n",
      " ['7->0' '7->1' '7->2' '7->3' '7->4' '7->5' '7->6' '7->7' '7->8']\n",
      " ['8->0' '8->1' '8->2' '8->3' '8->4' '8->5' '8->6' '8->7' '8->8']]\n"
     ]
    }
   ],
   "source": [
    "# THIS SIMPLE CODE JUST SHOWS THE STATE TRANSITION MAPPINGS FOR THE TRANSITION MATRIX\n",
    "tmp=[]\n",
    "for i in range(0,m*m):\n",
    "    tmp2=[]\n",
    "    for j in range(0,m*m):\n",
    "        tmp2.append(str(i)+\"->\"+str(j))\n",
    "    tmp.append(tmp2)\n",
    "tmp=np.array(tmp)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code example: numpy\n",
    "\n",
    "For positive integers n, the power is computed by repeated matrix squarings and matrix multiplications. If n == 0, the identity matrix of the same shape as M is returned. If n < 0, the inverse is computed and then raised to the abs(n).\n",
    "\n",
    "```\n",
    "linalg.matrix_power(a, n) --> Raise a square matrix to the (integer) power n.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:\n",
      " [[0.39728021 0.18775211 0.3050724 ]\n",
      " [0.71696446 0.6222347  0.82518232]\n",
      " [0.51930807 0.00771829 0.77566512]]\n",
      "\n",
      "A**2.0 (component wise square): \n",
      " [[1.57831562e-01 3.52508559e-02 9.30691677e-02]\n",
      " [5.14038033e-01 3.87176020e-01 6.80925858e-01]\n",
      " [2.69680875e-01 5.95720452e-05 6.01656374e-01]]\n",
      "\n",
      "np.matmul(A,A): \n",
      " [[0.45086971 0.19377072 0.51276297]\n",
      " [1.15947979 0.52815661 1.37224828]\n",
      " [0.61465372 0.10829059 0.76645193]]\n",
      "\n",
      "np.linalg.matrix_power(A,2): \n",
      " [[0.45086971 0.19377072 0.51276297]\n",
      " [1.15947979 0.52815661 1.37224828]\n",
      " [0.61465372 0.10829059 0.76645193]]\n"
     ]
    }
   ],
   "source": [
    "A=np.random.uniform(0,1,(3,3))\n",
    "print(\"ORIGINAL:\\n\",A)\n",
    "print(\"\\nA**2.0 (component wise square): \\n\",A**2.0)\n",
    "print(\"\\nnp.matmul(A,A): \\n\",np.matmul(A,A))\n",
    "print(\"\\nnp.linalg.matrix_power(A,2): \\n\",np.linalg.matrix_power(A,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Follow the instructions in the comments "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-0:  Simulate the robot\n",
    "\n",
    "* Lets simulate the broken robot \n",
    "* To estimate the steady state occupation probabilities, we can simply simulate the system for a long enough time so that the probabilities eventually converge.  \n",
    "* The function inputs are \n",
    "  * The grid size $m=3$ $\\rightarrow$ $m \\times m=3 \\times 3$\n",
    "  * The probability $p$ for up,down,left,right moves\n",
    "  * The initial probabilities distribution vector $q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE TO SIMULATE THE BROKEN ROBOT GIVEN THE INPUTS\n",
    "    # YOU SHOULD ACTUALLY SIMULATE THE PROCESS BY HAVING THE ROBOT \"WALK\" AROUND \n",
    "    # THE SPACE INSIDE A TIME LOOP BASED ON THE p=[pu,pd,pl,pr=0.25]\n",
    "    # ALSO CODED SO IT \"BOUNCES\" OFF WHEN IT STEPS INTO A WALL AND RETURNS TO THE ORIGINAL CELL\n",
    "# THE FUNCTION SHOULD OUTPUT TWO THINGS\n",
    "    # 1) THE TIME-AVERAGE OCCUPATION PROBABILITY FOR EACH STATE (STORED AS AN m by m MATRIX)\n",
    "    # 2) THE OCCUPIED STATE AT THE nth TIME-STEP (STORED AS AN m by m MATRIX OF ZEROS AND ONES)\n",
    "\n",
    "def simulate_robot(n=100000,m=3,q=[0,0,0,0,1,0,0,0,0], p = [0.2, 0.3, 0.25, 0.25]):\n",
    "    # n=NUMBER OF TIME-STEPS\n",
    "    # q=INITIALIZATION PROBABILITY: IC MUST BE A VECTOR OF LENGTH (m**2,1) WHICH SUMS TO 1\n",
    "    # p=[pu=0.2; pd=0.3; pl=0.25; pr=0.25];  \n",
    "\n",
    "    # INSERT YOUR CODE\n",
    "    Nn = np.array(q).reshape((m,m))\n",
    "    Ns = np.array(q).reshape((m,m))\n",
    "    \n",
    "    for _ in range(n):\n",
    "        move = np.random.choice([\"Up\",\"Down\",\"Left\",\"Right\"], p=p)\n",
    "        idx = np.where(Nn==1)\n",
    "        if move == \"Up\":\n",
    "            if idx[0]-1 < 0:\n",
    "                Nn = Nn\n",
    "            else:\n",
    "                Nn[idx] = 0\n",
    "                Nn[idx[0]-1,idx[1]] = 1\n",
    "                \n",
    "        elif move ==\"Down\":\n",
    "            if idx[0]+1 == 3:\n",
    "                Nn = Nn\n",
    "            else:\n",
    "                Nn[idx] = 0\n",
    "                Nn[idx[0]+1,idx[1]] = 1\n",
    "                \n",
    "        elif move == \"Left\":\n",
    "            if idx[1]-1 < 0:\n",
    "                Nn = Nn\n",
    "            else:\n",
    "                Nn[idx] = 0    \n",
    "                Nn[idx[0],idx[1]-1] = 1\n",
    "                \n",
    "        elif move == \"Right\":\n",
    "            if idx[1]+1 == 3:\n",
    "                Nn = Nn\n",
    "            else:\n",
    "                Nn[idx] = 0\n",
    "                Nn[idx[0],idx[1]+1] = 1\n",
    "        Ns = Ns + Nn\n",
    "    \n",
    "    \n",
    "    return [Ns/n,Nn]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-1: Compute time average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME-AVERAGED APPROXIMATE STEADY STATE DISTRIBUTIONS (50000 steps):\n",
      " [[0.07071 0.07097 0.07118]\n",
      " [0.10511 0.10341 0.10396]\n",
      " [0.16165 0.15529 0.15773]]\n"
     ]
    }
   ],
   "source": [
    "# TEST YOUR CODE\n",
    "print(\"TIME-AVERAGED APPROXIMATE STEADY STATE DISTRIBUTIONS (50000 steps):\\n\",simulate_robot(m=m,q=q,p=p)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-2: Compute ensemble average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE TO CALCULATE THE ENSEMBLE AVERAGE OCCUPATION AT THE nth TIME-STEP\n",
    "# DO THIS BY RUNNING MANY SHORT SIMULATIONS MANY TIMES (e.g. 10000 times)\n",
    "# THIS CAN BE DONE BY STARTING FROM RANDOM INITIAL CONDITIONS OR BY STARTING FROM THE SAME INITIAL CONDITION EACH TIME\n",
    "def ensemble_ave(n,q=q):\n",
    "    ens = np.zeros((3,3))\n",
    "    for _ in range(10000):\n",
    "        ens = ens + simulate_robot(n=n,q=q)[1]\n",
    "    print(\"SIMULATION ENSEMBLE AVERAGE AT TIMESTEP n =\",n,\":\\n\",ens/10000,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMULATION ENSEMBLE AVERAGE AT TIMESTEP n = 1 :\n",
      " [[0.     0.2032 0.    ]\n",
      " [0.2512 0.     0.2498]\n",
      " [0.     0.2958 0.    ]] \n",
      "\n",
      "SIMULATION ENSEMBLE AVERAGE AT TIMESTEP n = 2 :\n",
      " [[0.0977 0.042  0.102 ]\n",
      " [0.0621 0.2422 0.0616]\n",
      " [0.1502 0.0925 0.1497]] \n",
      "\n",
      "SIMULATION ENSEMBLE AVERAGE AT TIMESTEP n = 20 :\n",
      " [[0.0709 0.0716 0.0732]\n",
      " [0.1054 0.1011 0.102 ]\n",
      " [0.1586 0.1587 0.1585]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TEST YOUR CODE (ASSUMING YOU START IN THE CENTER EACH TIME) \n",
    "\n",
    "ensemble_ave(1)\n",
    "#  n=1 expected\n",
    "#  [[0.   0.2  0.  ]\n",
    "#  [0.25 0.   0.25]\n",
    "#  [0.   0.3  0.  ]] \n",
    "\n",
    "ensemble_ave(2)\n",
    "#  n=2 expected\n",
    "#  [[0.1    0.04   0.1   ]\n",
    "#  [0.0625 0.245  0.0625]\n",
    "#  [0.15   0.09   0.15  ]] \n",
    "\n",
    "# Notice that at the 20th time step the ensemble average has approximately converge to the time average, since our system is highly ergodic\n",
    "ensemble_ave(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-3:  Matrix multiplication method\n",
    "\n",
    "- We can also use matrix multiplication to determine state occupation probability $\\mathbf q_n$ at the $n^{th}$ time-step: $\\mathbf q_n  = \\mathbf q_{n-1} \\mathbf P$\n",
    "- **Notice that the matrix multiplication has the effect of statistically progressing the system forward in time. It updates the state occupation probabilities to the next time step, resulting in a new vector, similar to the initial condition probabilities $\\mathbf q_0$**\n",
    "-  We can use this formula recursively, starting from the probability vector $\\mathbf q_0$ \n",
    "$$\\mathbf q_n  = \\mathbf q_{0} \\mathbf P^n$$\n",
    "- Where $\\mathbf q_0$ is the initial probability distribution and $\\mathbf P^n$ is the transition probability matrix applied repeatably with $n$ matrix multiplications\n",
    "- This is equivalent to the ensemble average discussed above at the $n^{th}$ time step\n",
    "- Again $\\mathbf q_n$ is the probability of the system being in state $i$ after $n$ steps. This is equivalent to the probability of the system transitioning from $\\mathbf q_{n-1}$ to $\\,\\mathbf q_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE TO PREDICT THE OCCUPATION PROBABILITY AT STEP N USING MATRIX MULTIPLICATION\n",
    "def occupation(q, P, n):\n",
    "    current = q\n",
    "    for _ in range(n):\n",
    "        current = np.dot(current,P)\n",
    "    return current.reshape(3,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- n=1 --------\n",
      "SIMULATION ENSEMBLE AVERAGE AT TIMESTEP n = 1 :\n",
      " [[0.     0.1943 0.    ]\n",
      " [0.2526 0.     0.2471]\n",
      " [0.     0.306  0.    ]] \n",
      "\n",
      "\n",
      "MATRIX MULTIPLY:\n",
      "[[0.   0.2  0.  ]\n",
      " [0.25 0.   0.25]\n",
      " [0.   0.3  0.  ]]\n",
      "\n",
      "------- n=3 --------\n",
      "SIMULATION ENSEMBLE AVERAGE AT TIMESTEP n = 3 :\n",
      " [[0.0679 0.1002 0.063 ]\n",
      " [0.1366 0.0611 0.1391]\n",
      " [0.1231 0.1794 0.1296]] \n",
      "\n",
      "\n",
      "MATRIX MULTIPLY:\n",
      "[[0.0675   0.107    0.0675  ]\n",
      " [0.136875 0.06125  0.136875]\n",
      " [0.12375  0.1755   0.12375 ]]\n",
      "\n",
      "------- n=20 --------\n",
      "SIMULATION ENSEMBLE AVERAGE AT TIMESTEP n = 20 :\n",
      " [[0.0671 0.0743 0.0714]\n",
      " [0.1061 0.1011 0.1093]\n",
      " [0.1575 0.1583 0.1549]] \n",
      "\n",
      "\n",
      "MATRIX MULTIPLY:\n",
      "[[0.07025689 0.07025666 0.07025689]\n",
      " [0.10528127 0.10528179 0.10528127]\n",
      " [0.15779517 0.15779489 0.15779517]]\n"
     ]
    }
   ],
   "source": [
    "## TEST YOUR CODE \n",
    "P = get_P(m, p)\n",
    "\n",
    "# TRY DIFFERENT VALUES OF n\n",
    "for n in [1,3,20]:\n",
    "    # print('n = {}\\n'.format(n))\n",
    "    print(\"\\n------- n=\"+str(n)+\" --------\")\n",
    "    ensemble_ave(n,q=q)\n",
    "    print(\"\\nMATRIX MULTIPLY:\")\n",
    "    print(occupation(q=q, P=P, n=n))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-4: Eigen-vector method\n",
    "\n",
    "- There is a third way to calculate the steady-state occupation probability $\\mathbf p_n$ as $n \\rightarrow \\infty$\n",
    "- The definition of steady state means the the updated $\\mathbf q$ vector stops changing with time, i.e. with repeated matrix multiplication.\n",
    "- mathematically this means $\\mathbf q_{n+1}=\\mathbf q_n$ can be stated as\n",
    "$$\\mathbf q_{n+1} \\mathbf P = \\mathbf q_n \\rightarrow  \\mathbf q_n \\mathbf P = \\mathbf q_n$$\n",
    "- This is known as a left-hand eigenvalue problem, which is similar to the right hand eigenvalue problem which you are probably familiar with. You can switch between the two using the matrix transpose!\n",
    "$$ \\mathbf P^T \\mathbf q = \\mathbf q$$\n",
    "- for a system with $m^2$ states there will be $m^2$ eigenvalues and $m^2$ eigenvectors.\n",
    "- One of these eigenvalues will be equal to one, the eigenvector associated with this eigenvalue is the vector of steady-state probabilities\n",
    "- It is easiest to just see this demonstrated in an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATRIX MULTIPLICATION METHOD (n=100) \n",
      " [[0.07025689 0.07025666 0.07025689]\n",
      " [0.10528127 0.10528179 0.10528127]\n",
      " [0.15779517 0.15779489 0.15779517]] \n",
      "\n",
      "EIGEN VALUE/VECTOR METHOD (n=100)\n",
      "eigen-values: \n",
      " [-0.49494897  1.          0.75        0.74494897  0.49494897 -0.00505103\n",
      "  0.00505103  0.25505103  0.25      ] \n",
      "\n",
      "eigen-vector for eval=1: \n",
      " [[0.07017544 0.07017544 0.07017544]\n",
      " [0.10526316 0.10526316 0.10526316]\n",
      " [0.15789474 0.15789474 0.15789474]]\n"
     ]
    }
   ],
   "source": [
    "# INSERT CODE TO COMPUTE THE STEADY STATE OCCUPATION PROBABILITIES \n",
    "# FOR THE MARK OFF CHAIN USING THE EIGEN-VALUE METHOD\n",
    "# SO INCLUDE CODE TO COMPARE IT TO THE MATRIX MULTIPLICATION METHOD WITHIN N=100\n",
    "w,v = np.linalg.eig(get_P(m,p).T)\n",
    "print(\"MATRIX MULTIPLICATION METHOD (n=100) \\n\",occupation(q=q, P=P, n=n),\"\\n\")\n",
    "print(\"EIGEN VALUE/VECTOR METHOD (n=100)\")\n",
    "print(\"eigen-values: \\n\",w,\"\\n\")\n",
    "print(\"eigen-vector for eval=1: \\n\",(v[:,1]/v[:,1].sum()).reshape(m,m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b296f35070df721027705735a60360cba429fd2667f42ac80b08fc45ece0957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
